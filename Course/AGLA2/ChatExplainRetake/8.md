# Task 8 Vector Differential Equations

## TOC

- [Task 8 Vector Differential Equations](#task-8-vector-differential-equations)
  - [TOC](#toc)
  - [Explanation](#explanation)
    - [Basics of Vector Functions](#basics-of-vector-functions)
    - [Differentiation of Vector Functions](#differentiation-of-vector-functions)
    - [Vector Differential Equations](#vector-differential-equations)
    - [Applications](#applications)
    - [Linear vs. Nonlinear](#linear-vs-nonlinear)
  - [Solution](#solution)

## Explanation

Certainly! Vector differential equations are a type of differential equation where the functions involved are vector functions rather than scalar functions. This means that instead of dealing with functions that output a single value, we deal with functions that output a vector of values. These kinds of equations are especially important in physics and engineering where systems are often described in terms of their vector fields, like electromagnetic fields, fluid flow, and forces in mechanics.

### Basics of Vector Functions

A vector function $\mathbf{r}(t)$ is typically defined as a function that depends on a scalar parameter $t$ (which could be time, for instance), and outputs a vector. For example, in three-dimensional space, a vector function could be written as:

$$
\mathbf{r}(t) = \begin{bmatrix}
f_1(t) \\
f_2(t) \\
f_3(t)
\end{bmatrix}
$$

where $f_1(t)$, $f_2(t)$, and $f_3(t)$ are the scalar component functions, which could be functions of time that describe the path of a particle in space.

### Differentiation of Vector Functions

The derivative of a vector function with respect to $t$ is defined component-wise. If we have a vector function $\mathbf{r}(t)$ as above, its derivative is given by:

$$
\frac{d\mathbf{r}}{dt} = \begin{bmatrix}
\frac{df_1}{dt}(t) \\
\frac{df_2}{dt}(t) \\
\frac{df_3}{dt}(t)
\end{bmatrix}
$$

This derivative gives the rate of change of the vector function with respect to time.

### Vector Differential Equations

A vector differential equation involves vector functions and their derivatives. For example, a first-order vector differential equation has the general form:

$$
\frac{d\mathbf{r}}{dt} = \mathbf{f}(\mathbf{r}, t)
$$

where $\mathbf{f}(\mathbf{r}, t)$ is a vector field that could depend on both the vector $\mathbf{r}$ and the scalar $t$.

Solving a vector differential equation typically means finding a vector function $\mathbf{r}(t)$ that satisfies the equation for all $t$ in some interval.

### Applications

In physics, vector differential equations are used to describe many types of dynamical systems. For instance:

- **Newton's Second Law** can be written as a vector differential equation $m\frac{d^2\mathbf{r}}{dt^2} = \mathbf{F}$, where $m$ is the mass of a particle, $\frac{d^2\mathbf{r}}{dt^2}$ is the acceleration vector, and $\mathbf{F}$ is the force vector acting on the particle.

- **Maxwell's Equations** in electrodynamics can be formulated as a set of vector differential equations describing how electric and magnetic fields ($\mathbf{E}$ and $\mathbf{B}$) evolve over time and space.

- **Navier-Stokes Equations** for fluid dynamics are another example, representing the motion of fluid substances.

### Linear vs. Nonlinear

Vector differential equations can be linear or nonlinear, depending on whether the function $\mathbf{f}(\mathbf{r}, t)$ is linear in $\mathbf{r}$ or not. Linear vector differential equations have solutions that exhibit superposition, which means the sum of any two solutions is also a solution. Nonlinear vector differential equations are more complex and often require numerical methods for their solutions.

Solving vector differential equations can involve various methods, including analytical techniques for simpler, linear problems, and numerical simulations for more complex, nonlinear problems. Tools such as matrix algebra, eigenvalue problems, and the theory of dynamical systems are often employed in the analysis of these equations.

## Solution

8. Solve the differential equation, (10 pts.):
   $$
   \frac{d\vec{u}}{dt}=\begin{bmatrix}4&-2\\1&1\end{bmatrix}\vec{u}(t), \vec{u}(0)=\begin{bmatrix}3\\2\end{bmatrix}
   $$
   What happens to $\vec{u}(t)$ as $t\rightarrow \infty$ ? (2 pts.)

To solve the given linear homogeneous differential equation

$$
\frac{d\vec{u}}{dt} = \begin{bmatrix} 4 & -2 \\ 1 & 1 \end{bmatrix}\vec{u}(t), \quad \vec{u}(0) = \begin{bmatrix} 3 \\ 2 \end{bmatrix}
$$

we can use the method of eigenvalues and eigenvectors. The general solution to such an equation involves finding the eigenvalues $\lambda$ and corresponding eigenvectors $\vec{v}$ of the matrix

$$
A = \begin{bmatrix} 4 & -2 \\ 1 & 1 \end{bmatrix}
$$

The eigenvalues are found by solving the characteristic equation

$$
\det(A - \lambda I) = 0
$$

where $I$ is the identity matrix. Once we have the eigenvalues, we can find the corresponding eigenvectors by solving the equation

$$
(A - \lambda I)\vec{v} = 0
$$

The general solution to the differential equation will be a linear combination of the eigenvectors multiplied by exponential factors involving the eigenvalues and time $t$.

Let's proceed by calculating the eigenvalues and eigenvectors of the matrix $A$.

The matrix has two eigenvalues, $\lambda_1 = 3$ and $\lambda_2 = 2$, with corresponding eigenvectors

$$
\vec{v}_1 = \begin{bmatrix} 0.8944 \\ 0.4472 \end{bmatrix}, \quad \vec{v}_2 = \begin{bmatrix} 0.7071 \\ 0.7071 \end{bmatrix}
$$

These eigenvectors are normalized. For our purposes, we don't necessarily need normalized eigenvectors, but any non-zero scalar multiples of these will work as well.

The general solution to the differential equation is then a combination of terms of the form $e^{\lambda t} \vec{v}$, so our solution will look like:

$$
\vec{u}(t) = c_1 e^{\lambda_1 t} \vec{v}_1 + c_2 e^{\lambda_2 t} \vec{v}_2
$$

where $c_1$ and $c_2$ are constants that we determine from the initial condition $\vec{u}(0) = \begin{bmatrix} 3 \\ 2 \end{bmatrix}$.

We need to solve for $c_1$ and $c_2$ by setting $t = 0$ in the general solution and using the given initial condition:

$$
\vec{u}(0) = c_1 \vec{v}_1 + c_2 \vec{v}_2 = \begin{bmatrix} 3 \\ 2 \end{bmatrix}
$$

Let's do that now.

The constants $c_1$ and $c_2$ are found to be approximately $c_1 = 2.2361$ and $c_2 = 1.4142$.

Now we can write down the explicit solution for $\vec{u}(t)$:

$$
\vec{u}(t) = 2.2361 e^{3t} \begin{bmatrix} 0.8944 \\ 0.4472 \end{bmatrix} + 1.4142 e^{2t} \begin{bmatrix} 0.7071 \\ 0.7071 \end{bmatrix}
$$

To determine what happens to $\vec{u}(t)$ as $t \to \infty$, we look at the eigenvalues. Both are positive, which means that each term in the solution grows exponentially with time. The term with the larger eigenvalue ($\lambda_1 = 3$) will dominate as $t \to \infty$, causing $\vec{u}(t)$ to grow without bound in the direction of its corresponding eigenvector $\vec{v}_1$.

Would you like to see the explicit form of the vector $\vec{u}(t)$ written out, or do you have any further questions on this topic?

The explicit form of the vector function $\vec{u}(t)$ is:

$$
\vec{u}(t) = \begin{bmatrix}
2.0 e^{3t} + 1.0 e^{2t} \\
1.0 e^{3t} + 1.0 e^{2t}
\end{bmatrix}
$$

This representation shows the two components of the vector $\vec{u}(t)$, with each component being a sum of two exponential terms. As $t \to \infty$, both components of $\vec{u}(t)$ will grow exponentially, with the term involving $e^{3t}$ dominating due to its larger exponent.
